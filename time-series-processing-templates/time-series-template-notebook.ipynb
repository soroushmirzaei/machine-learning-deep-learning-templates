{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "time-series-notebook-template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7mnoP3nmNCTJwAj+luhIY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soroushmirzaei/projects-notebook-templates/blob/main/time-series-processing-templates/time-series-notebook-template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "degYQS5RD6f6"
      },
      "outputs": [],
      "source": [
        "#import requirement libraries\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "#import dataset query libraries\n",
        "import csv\n",
        "import json\n",
        "\n",
        "#import mathematics statistics libraries\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#import machine learning deep learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define text, csv and json files loader\n",
        "def dataset_loader(#define file path and file type\n",
        "                   file_path, file_type, time_dummies = False,\n",
        "                   #define txt and csv file params\n",
        "                   time_index = None, series_index = None, header = True, separator_delimiter = None,\n",
        "                   #define json file params\n",
        "                   time_key = None, series_key = None\n",
        "                   ):\n",
        "    \n",
        "    #initialize time and series lists\n",
        "    time_list = list()\n",
        "    series_list = list()\n",
        "\n",
        "    #define comma separated values file loader\n",
        "    if file_type in ['csv']:\n",
        "        with open(file_path, 'r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter = separator_delimiter)\n",
        "            if header:\n",
        "                next(csv_reader)\n",
        "            for row in csv_reader:\n",
        "                if not time_dummies:\n",
        "                    time_list.append(int(row[time_index]))\n",
        "                series_list.append(float(row[series_index]))\n",
        "        csv_file.close()\n",
        "    \n",
        "    #define java script object notation file loader\n",
        "    elif file_type in ['json']:\n",
        "        with open(file_path, 'r') as json_file:\n",
        "            json_reader = json.load(json_file)\n",
        "            for item in json_reader:\n",
        "                if not time_dummies:\n",
        "                    time_list.append(int(item[time_key]))\n",
        "                series_list.append(float(item[series_key]))\n",
        "        json_file.close()\n",
        "\n",
        "    #define text file loader\n",
        "    elif file_type in ['txt']:\n",
        "        with open(file_path, 'r') as txt_file:\n",
        "            for row in txt_file:\n",
        "                row = row.split(separator_delimiter)\n",
        "                if not time_dummies:\n",
        "                    time_list.append(int(row[time_index]))\n",
        "                series_list.append(float(row[series_index]))\n",
        "\n",
        "    if time_dummies:\n",
        "        time_list = [time for time in range(len(series_list))]\n",
        "\n",
        "    return time_list, series_list\n",
        "    "
      ],
      "metadata": {
        "id": "_tHIeV56_xTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define split train valid time series\n",
        "def train_valid_periods(#define series\n",
        "                        time, series,\n",
        "                        #define split time\n",
        "                        split_time\n",
        "                        ):\n",
        "    \n",
        "    #split train periods\n",
        "    train_time = time[:split_time]\n",
        "    train_series = series[:split_time]\n",
        "\n",
        "    #split valid periods\n",
        "    valid_time = time[split_time:]\n",
        "    valid_series = series[split_time:]\n",
        "\n",
        "    return train_time, train_series, valid_time, valid_series\n",
        "    "
      ],
      "metadata": {
        "id": "rZ4nMj71QDPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define time series window dataset\n",
        "def window_dataset(#define series list or array or series\n",
        "                   series,\n",
        "                   #define windowing parameters\n",
        "                   window_size, shift = 1, stride = 1,\n",
        "                   #define shuffle buffer and batch size\n",
        "                   shuffle_buffer = None, batch_size = None):\n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size + 1, shift = shift, stride = stride, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window : window.batch(window_size + 1))\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "    dataset = dataset.map(lambda window : (window[:-1], window[-1]))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset\n",
        "    "
      ],
      "metadata": {
        "id": "GZaReDnPP_le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define windowing and split params\n",
        "split_time = None\n",
        "window_size = None\n",
        "batch_size = None\n",
        "shuffle_buffer = None\n"
      ],
      "metadata": {
        "id": "ehlU_OZhHjAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split train valid\n",
        "train_time, train_series, valid_time, valid_series = train_valid_periods(time = time_list, series = series_list,\n",
        "                                                                         split_time = split_time)\n"
      ],
      "metadata": {
        "id": "OC15xTtbLm9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#windowing train valid series\n",
        "train_dataset = window_dataset(series = train_series,\n",
        "                               window_size = window_size, shift = 1, stride = 1,\n",
        "                               shuffle_buffer = shuffle_buffer, batch_size = batch_size)\n",
        "valid_dataset = window_dataset(series = valid_series,\n",
        "                               window_size = window_size, shift = 1, stride = 1,\n",
        "                               shuffle_buffer = shuffle_buffer, batch_size = batch_size)\n"
      ],
      "metadata": {
        "id": "zQbuCD7HMT4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define create model\n",
        "def create_model(#define window_size as sequence length\n",
        "                 window_size, feature_num, \n",
        "                 #define types of layers\n",
        "                 use_conv = False, use_lstm = False, use_gru = False, use_rnn = False,\n",
        "                 use_dense = False, use_rescale = False,\n",
        "                 #define convolution layers params\n",
        "                 conv_layers_num = None, conv_layers_filters = None, conv_layers_kernel = None,\n",
        "                 #define lstm layers params\n",
        "                 lstm_layers_num = None, lstm_layers_units = None, lstm_return_seq = False,\n",
        "                 #define gru layers params\n",
        "                 gru_layers_num = None, gru_layers_units = None, gru_return_seq = False,\n",
        "                 #define rnn layers params\n",
        "                 rnn_layers_num = None, rnn_layers_units = None, rnn_return_seq = False,\n",
        "                 #define dense layers params\n",
        "                 dense_layers_num = None, dense_layers_units = None, dense_activation = 'relu',\n",
        "                 #define output layer params\n",
        "                 output_layer_units = None, output_activation = 'relu',\n",
        "                 #define reshape and rescale params\n",
        "                 rescale_value = None, reshape_features = None\n",
        "                 ):\n",
        "    \n",
        "    #define input layer and reshape layers\n",
        "    inp = keras.Input([window_size])\n",
        "    out = keras.layers.Reshape((-1, reshape_features))(inp)\n",
        "\n",
        "    #define convolution layers\n",
        "    if use_conv:\n",
        "        for layer_num in range(conv_layers_num):\n",
        "            out = keras.layers.Conv1D(conv_layers_filters[layer_num], conv_layers_kernel[layer_num],\n",
        "                                      padding = 'causal', activation = 'relu')(out)\n",
        "    \n",
        "    #define lstm layers\n",
        "    if use_lstm:\n",
        "        for layer_num in range(lstm_layers_num):\n",
        "            if layer_num < lstm_layers_num - 1:\n",
        "                out = keras.layers.Bidirectional(keras.layers.LSTM(lstm_layers_units[layer_num], return_sequences = True))(out)\n",
        "            elif layer_num == lstm_layers_num - 1 and not lstm_return_seq:\n",
        "                out = keras.layers.Bidirectional(keras.layers.LSTM(lstm_layers_units[layer_num]))(out)\n",
        "            elif layer_num == lstm_layers_num - 1 and lstm_return_seq:\n",
        "                out = keras.layers.Bidirectional(keras.layers.LSTM(lstm_layers_units[layer_num], return_sequences = True))(out)\n",
        "    \n",
        "    #define gru layers\n",
        "    if use_gru:\n",
        "        for layer_num in range(gru_layers_num):\n",
        "            if layer_num < gru_layers_num - 1:\n",
        "                out = keras.layers.Bidirectional(keras.layers.GRU(gru_layers_units[layer_num], return_sequences = True))(out)\n",
        "            elif layer_num == gru_layers_num - 1 and not gru_return_seq:\n",
        "                out = keras.layers.Bidirectional(keras.layers.GRU(gru_layers_units[layer_num]))(out)\n",
        "            elif layer_num == gru_layers_num - 1 and gru_return_seq:\n",
        "                out = keras.layers.Bidirectional(keras.layers.GRU(gru_layers_units[layer_num], return_sequences = True))(out)\n",
        "\n",
        "    #define gru layers\n",
        "    if use_rnn:\n",
        "        for layer_num in range(rnn_layers_num):\n",
        "            if layer_num < rnn_layers_num - 1:\n",
        "                out = keras.layers.SimpleRNN(rnn_layers_units[layer_num], return_sequences = True)(out)\n",
        "            elif layer_num == rnn_layers_num - 1 and not rnn_return_seq:\n",
        "                out = keras.layers.SimpleRNN(rnn_layers_units[layer_num])(out)\n",
        "            elif layer_num == rnn_layers_num - 1 and rnn_return_seq:\n",
        "                out = keras.layers.SimpleRNN(rnn_layers_units[layer_num], return_sequences = True)(out)\n",
        "\n",
        "    #define desne layers\n",
        "    if use_dense:\n",
        "        for layer_num in range(dense_layers_num):\n",
        "            out = keras.layers.Dense(dense_layers_units[layer_num], activation = dense_activation)(out)\n",
        "\n",
        "    #define output layer\n",
        "    out = keras.layers.Dense(output_layer_units, activation = output_activation)(out)\n",
        "\n",
        "    #define rescale layer\n",
        "    if use_rescale:\n",
        "        out = keras.layers.Rescaling(rescale_value)(out)\n",
        "\n",
        "    #build model\n",
        "    model = keras.Model(inp, out)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "BkUj5C7eDLEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define model compiler\n",
        "def compile_model(#define model\n",
        "                  model,\n",
        "                  #define optimizer loss and metrics\n",
        "                  optimizer, loss, metrics\n",
        "                  ):\n",
        "    \n",
        "    #define model compiler params optimizer, loss and metrics\n",
        "    model.compile(optimizer = optimizer,\n",
        "                  loss = loss,\n",
        "                  metrics = metrics)\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "UtcM9OcofshK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define learning rate tunning function and plot\n",
        "def learinig_rate_tunner(#define model\n",
        "                         model,\n",
        "                         #define learning rate bounds\n",
        "                         up_bound, low_bound,\n",
        "                         #define fit params\n",
        "                         train_dataset, valid_dataset, epochs,\n",
        "                         #define use init weights or not\n",
        "                         use_init_weights = False\n",
        "                         ):\n",
        "    \n",
        "    #define learning rate schedular and its constant\n",
        "    constant = epochs / np.log10(up_bound / low_bound)\n",
        "    lr_schedule = keras.callbacks.LearningRateScheduler(lambda epoch : low_bound * np.power(10, (epoch / constant)))\n",
        "    \n",
        "    #get init weights\n",
        "    init_weights = model.get_weights()\n",
        "\n",
        "    #define custon callback to set init weights\n",
        "    class InitWeightsLoader(keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs = None):\n",
        "            model.set_weights(init_weights)\n",
        "    init_weights = InitWeightsLoader()\n",
        "\n",
        "    #fit the model\n",
        "    if use_init_weights:\n",
        "        history = model.fit(train_dataset, validation_data = (valid_dataset),\n",
        "                            epochs = epochs, callbacks = [init_weights, lr_schedule], verbose = 0)\n",
        "    else:\n",
        "        history = model.fit(train_dataset, validation_data = (valid_dataset),\n",
        "                            epochs = epochs, callbacks = [lr_schedule], verbose = 0)\n",
        "\n",
        "    #plot the learning rate versus loss\n",
        "    plt.figure(figsize = (12, 9))\n",
        "    sns.lineplot(x = history.history['lr'], y = history.history['loss'])\n",
        "    plt.xscale('log')\n",
        "    plt.xlabel('Learning Rate [log]'); plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "RGwHbfk8SeUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define model and tunning the learning rate\n",
        "model = create_model(window_size = window_size, feature_num = None,\n",
        "                     use_conv = True, use_lstm = True, use_gru = False, use_rnn = False,\n",
        "                     use_dense = True, use_rescale = True,\n",
        "                     conv_layers_num = None, conv_layers_filters = None, conv_layers_kernel = None,\n",
        "                     lstm_layers_num = None, lstm_layers_units = None, lstm_return_seq = False,\n",
        "                     gru_layers_num = None, gru_layers_units = None, gru_return_seq = False,\n",
        "                     rnn_layers_num = None, rnn_layers_units = None, rnn_return_seq = False,\n",
        "                     dense_layers_num = None, dense_layers_units = None,\n",
        "                     output_layer_units = None, rescale_value = None, reshape_features = None)\n",
        "\n",
        "#compile model\n",
        "model = compile_model(model = model,\n",
        "                      optimizer = None,\n",
        "                      loss = None,\n",
        "                      metrics = None)\n",
        "\n",
        "#model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "xwggX2zmbOpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get weights\n",
        "init_weights = model.get_weights()\n"
      ],
      "metadata": {
        "id": "E1Gy5QOGpueZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot learning rate\n",
        "learinig_rate_tunner(model = model,\n",
        "                     up_bound = None, low_bound = None,\n",
        "                     train_dataset = train_dataset, valid_dataset = train_dataset, epochs = None,\n",
        "                     use_init_weights = False)\n"
      ],
      "metadata": {
        "id": "Glgx9yXRpYB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model and fit based on learning rate\n",
        "keras.backend.clear_session()\n",
        "model.set_weights(init_weights)\n",
        "\n",
        "#optimal learning rate\n",
        "learning_rate = None\n",
        "\n",
        "model = compile_model(model = model,\n",
        "                      optimizer = None,\n",
        "                      loss = None,\n",
        "                      metrics = None)\n",
        "\n",
        "history = model.fit(None, validation_data = None,\n",
        "                    epochs = None, verbose = None)\n"
      ],
      "metadata": {
        "id": "fRyvudQeregz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Plot Model Metrics"
      ],
      "metadata": {
        "id": "nPVhEkP9LuZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot model loss and metrics\n",
        "def plot_model(#define model history\n",
        "               history,\n",
        "               #define param to plot\n",
        "               param,\n",
        "               #define axis lim\n",
        "               x_low = None, x_high = None,\n",
        "               y_low = None, y_high = None,\n",
        "               ):\n",
        "    \n",
        "    plt.figure(figsize = (12, 9))\n",
        "    sns.lineplot(x = np.arange(len(history.history[param])), y = history.history[param])\n",
        "    plt.xlabel('Epoch'); plt.ylabel(param.title()); plt.xlim(x_low,x_high); plt.ylim(y_low, y_high); plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "jpSMd-B8sOL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Model Evaluation And Plot"
      ],
      "metadata": {
        "id": "xY_0yv3gL1Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define single time series prediction\n",
        "def single_predict(#define list or array\n",
        "                   time_array,\n",
        "                   #define model\n",
        "                   model, \n",
        "                   ):\n",
        "    \n",
        "    prediction = model.predict(np.expand_dims(time_array,0))\n",
        "    prediction = prediction.squeeze()\n",
        "\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "KvkrrbweDTGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define multiple time series prediction\n",
        "def model_forecast(#define list or array and params\n",
        "                   series_array, window_size, batch_size,\n",
        "                   #define model\n",
        "                   model\n",
        "                   ):\n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series_array)\n",
        "    dataset = dataset.window(window_size, shift = 1, stride = 1, drop_remainder = True)\n",
        "    dataset = dataset.flat_map(lambda window : window.batch(window_size))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "    forecast = model.predict(dataset).flatten()\n",
        "\n",
        "    return forecast\n"
      ],
      "metadata": {
        "id": "4U2xJUN2FiYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define plot evaluation\n",
        "def plot_series(#define series\n",
        "                time, series,\n",
        "                #define keywords of plot\n",
        "                x_label = None, y_label = None,\n",
        "                ):\n",
        "    \n",
        "    plt.figure(figsize = (12,9))\n",
        "    if type(series) in [list, set, tuple]:\n",
        "        for item in series:\n",
        "            sns.lineplot(x = time, y = item)\n",
        "    else:\n",
        "        sns.lineplot(x = time, y = series)\n",
        "    plt.xlabel(x_label.title()); plt.ylabel(y_label.title()); plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "NGKhFrDO2VxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forecast for train periods\n",
        "train_forecast_series = series_list[:split_time -1]\n",
        "train_forecast = model_forecast(series_array = train_forecast_series, window_size = window_size, batch_size = batch_size,\n",
        "                                model = model)\n",
        "\n",
        "plot_series(time = train_time[window_size:], series = (train_series[window_size:], train_forecast),\n",
        "            x_label = 'Time', y_label = 'Series')\n"
      ],
      "metadata": {
        "id": "6Sn_IxwA17kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forecast for valid periods\n",
        "valid_forecast_series = series_list[split_time - window_size: -1]\n",
        "valid_forecast = model_forecast(series_array = valid_forecast_series, window_size = window_size, batch_size = batch_size,\n",
        "                                model = model)\n",
        "\n",
        "plot_series(time = valid_time[:], series = (valid_series[:], valid_forecast),\n",
        "            x_label = 'Time', y_label = 'Series')\n",
        "                                "
      ],
      "metadata": {
        "id": "4-bVGStT6W7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forecast for total periods\n",
        "forecast_series = series_list[:-1]\n",
        "forecast = model_forecast(series_array = forecast_series, window_size = window_size, batch_size = batch_size,\n",
        "                          model = model)\n",
        "\n",
        "plot_series(time = time_list[window_size:], series = (series_list[window_size:], forecast),\n",
        "            x_label = 'Time', y_label = 'Series')\n",
        "                                "
      ],
      "metadata": {
        "id": "-BnLL6VV6Ytz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define train valid evaluation metrics based\n",
        "def evaluate_model(#define series\n",
        "                   series_array, forecast_array,\n",
        "                   #define evaluation metric \n",
        "                   metric\n",
        "                   ):\n",
        "    \n",
        "    if metric in ['mse','rmse']:\n",
        "        evaluate = keras.metrics.mean_squared_error(series_array, forecast_array).numpy()\n",
        "        if metric == 'rmse':\n",
        "            evaluate = np.power(evaluate, 0.5)\n",
        "    elif metric == 'mae':\n",
        "        evaluate = keras.metrics.mean_absolute_error(series_array, forecast_array).numpy()\n",
        "    elif metric == 'mape':\n",
        "        evaluate = keras.metrics.mean_absolute_percentage_error(series_array, forecast_array).numpy()\n",
        "    elif metric == 'msle':\n",
        "        evaluate = keras.metrics.mean_squared_logarithmic_error(series_array, forecast_array).numpy()\n",
        "    \n",
        "    abbr_dict = {\n",
        "        'm' : 'mean',\n",
        "        'r' : 'root',\n",
        "        's' : 'squared',\n",
        "        'a' : 'absolute',\n",
        "        'p' : 'percentage',\n",
        "        'l' : 'logarithmic',\n",
        "        'e' : 'error'\n",
        "    }\n",
        "    metric = ' '.join([abbr_dict[char] for char in list(metric)])\n",
        "    print(f'evaluation based on {metric}: {round(evaluate, 4)}')\n",
        "\n",
        "    return evaluate\n"
      ],
      "metadata": {
        "id": "j5JfXFzIYDZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model\n",
        "metric = None\n",
        "\n",
        "mae_train_eval = evaluate_model(series_array = train_series[window_size:], forecast_array = train_forecast, metric = metric)\n",
        "mae_valid_eval = evaluate_model(series_array = valid_series, forecast_array = valid_forecast, metric = metric)\n"
      ],
      "metadata": {
        "id": "ry5zvdDQArU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define future prediction function\n",
        "def future_predicture(#define model and series\n",
        "                      series, model, \n",
        "                      #define params\n",
        "                      window_size,\n",
        "                      #define counts of prediction\n",
        "                      prediction_count,\n",
        "                      #define return padded time and series\n",
        "                      padded_time_series = True\n",
        "                      ):\n",
        "    \n",
        "    prediction_series = series\n",
        "    future_forecast = list()\n",
        "\n",
        "    for time in range(len(prediction_series) - window_size, len(prediction_series) + prediction_count - window_size):\n",
        "        prediction = model.predict(np.expand_dims(series[time : time + window_size], 0))[0][0]\n",
        "        prediction_series.append(prediction)\n",
        "        future_forecast.append(prediction)\n",
        "\n",
        "    padded_series = prediction_series\n",
        "\n",
        "    if padded_time_series:\n",
        "        return future_forecast, padded_series\n",
        "    else:\n",
        "        return future_forecast\n"
      ],
      "metadata": {
        "id": "GAibCXq30go1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
