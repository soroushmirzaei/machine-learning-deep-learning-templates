{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image-classification-template-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soroushmirzaei/project-template-notebooks/blob/main/image-processing-templates/image-classification-template-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIYC55FdPdC2"
      },
      "outputs": [],
      "source": [
        "#import requirements libraries\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "#import mathematics statics libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#import machine learning deep learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip file\n",
        "def unzip(file_name, type_file = 'zip'):\n",
        "    cur_dir = os.getcwd()\n",
        "    file_path = os.path.join(cur_dir, f'{file_name}.{type_file}')\n",
        "    file = zipfile.ZipFile(file_path)\n",
        "    file.extractall(os.path.join(cur_dir, file_name))\n",
        "    file.close()\n"
      ],
      "metadata": {
        "id": "HyCTutUKsFm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove file with zero size\n",
        "def remove_file_zero(dir_path):\n",
        "    for root, dirs, files in os.walk(dir_path):\n",
        "        for file in files:\n",
        "            if os.path.getsize(os.path.join(root, file)) == 0:\n",
        "                os.remove(os.path.join(root, file))\n"
      ],
      "metadata": {
        "id": "7ZzOk7ckxEl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#romove other file type\n",
        "def remove_type(dir_path):\n",
        "    for root, dirs, files in os.walk(dir_path):\n",
        "        for file in files:\n",
        "            if file.split('.')[-1] not in ['jpg', 'jpeg', 'bmp', 'png', 'gif']:\n",
        "                os.remove(os.path.join(root, file))\n"
      ],
      "metadata": {
        "id": "9VOp3yjNyEkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rename file in label num format\n",
        "def rename_file(dir_path):\n",
        "    for label in os.listdir(dir_path):\n",
        "        num = 0\n",
        "        for file in os.scandir(os.path.join(dir_path, label)):\n",
        "            file_name = file.name\n",
        "            ext = file_name.split('.')[1]\n",
        "            num = num + 1\n",
        "            os.rename(file.path, os.path.join(dir_path, label, f'{label} {num}.{ext}'))\n"
      ],
      "metadata": {
        "id": "lCPfRfk3xsZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#capsfold file names\n",
        "def caps_file(dir_path):\n",
        "    for root, dirs, files in os.walk(dir_path):\n",
        "        for dir in dirs:\n",
        "            os.rename(os.path.join(root,dir), os.path.join(root,dir.title()))\n",
        "    for root, dirs, files in os.walk(dir_path):\n",
        "        for file in files:\n",
        "            os.rename(os.path.join(root,file), os.path.join(root,file.title()))\n"
      ],
      "metadata": {
        "id": "Kw70HvNs-_lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define training validation set\n",
        "Height = 150\n",
        "Width = 150\n",
        "\n",
        "train_gen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255, rotation_range = ,\n",
        "                                                         vertical_flip = , horizontal_flip = ,\n",
        "                                                         height_shift_range = , width_shift_range = ,\n",
        "                                                         shear_range = , zoom_range = , fill_mode = 'nearest')\n",
        "train_data = train_gen.flow_from_directory('',\n",
        "                                           target_size = (Height, Width), batch_size = 32,\n",
        "                                           color_mode = 'rgb', class_mode = 'sparse', seed = 0)\n",
        "\n",
        "valid_gen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255)\n",
        "valid_data = valid_gen.flow_from_directory('',\n",
        "                                           target_size = (Height, Width), batch_size = 32,\n",
        "                                           color_mode = 'rgb', class_mode = 'sparse', seed = 0)\n"
      ],
      "metadata": {
        "id": "BhK-i6rPvglQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define pretrained model\n",
        "pretrained_model = keras.applications.inception(input_shape = (Height, Width, 3),\n",
        "                                                include_top = False)\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "output_pre = pretrained_model.output\n"
      ],
      "metadata": {
        "id": "y2NwkVwpqKfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define custom pretrained model\n",
        "out_layer = pretrained_model.get_layer('')\n",
        "output_custom_pre = out_layer.output\n"
      ],
      "metadata": {
        "id": "z66jIDvpqw1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create model function\n",
        "def create_model(#convolution layer configuration\n",
        "                 conv_layers_num, conv_filters, conv_kernel_size, flatten_dropout_ratio, \n",
        "                 #dense layer configuration\n",
        "                 dense_layers_num, dense_units, dense_dropout_ratio,\n",
        "                 #output layer configuration\n",
        "                 out_dropout_ratio, out_units = train_data.num_classes,\n",
        "                 #activations configuration\n",
        "                 conv_activation = 'relu', dense_activation = 'relu', out_activation = 'softmax',\n",
        "\n",
        "                 #input shape\n",
        "                 inp_shape = (Height, Width, 3),\n",
        "\n",
        "                 #compiling Configuration\n",
        "                 compile_optimizer = 'adam', compile_loss ='sparse_categorical_crossentropy' ,\n",
        "                 compile_metric = ['accuracy'],\n",
        "                 \n",
        "                 #pretrained_model configuration\n",
        "                 flatten_input = None, pretrained_input = False,\n",
        "                 \n",
        "                 #convolution layers\n",
        "                 conv_base = True, batch_norm_conv = True,\n",
        "                 #flatten layer\n",
        "                 flatten_layer = True, flatten_dropout_out = True,\n",
        "                 #dense layers\n",
        "                 dense_head = True,  batch_norm_dense = True, dropout_dense = True,\n",
        "                 #output layer\n",
        "                 batch_norm_out = True, dropout_out = True\n",
        "                 ):\n",
        "\n",
        "    #define input layer\n",
        "    input = keras.Input(inp_shape)\n",
        "    out = input\n",
        "\n",
        "    #define convolution layers\n",
        "    if conv_base:\n",
        "        for i in range(conv_layers_num):\n",
        "            if batch_norm_conv:\n",
        "                out = keras.layers.BatchNormalization()(out)\n",
        "            out = keras.layers.Conv2D(filters = conv_filters[i],\n",
        "                                      kernel_size = conv_kernel_size[i], activation = conv_activation,\n",
        "                                      kernel_initializer = keras.initializers.GlorotNormal())(out)\n",
        "            out = keras.layers.MaxPool2D(pool_size = 2)(out)\n",
        "\n",
        "    #convert two dims to one dim\n",
        "    if flatten_layer:\n",
        "        try:\n",
        "            out = keras.layers.Flatten()(flatten_input)\n",
        "        except:\n",
        "            out = keras.layers.Flatten()(out)\n",
        "\n",
        "    if flatten_dropout_out:\n",
        "        out = keras.layers.Dropout(flatten_dropout_ratio)(out)\n",
        "\n",
        "    #define dense layers\n",
        "    if dense_head:\n",
        "        for i in range(dense_layers_num):\n",
        "            if batch_norm_dense:\n",
        "                out = keras.layers.BatchNormalization()(out)\n",
        "            out = keras.layers.Dense(units = dense_units[i], activation = dense_activation,\n",
        "                                     kernel_initializer = keras.initializers.HeNormal())(out)\n",
        "            if dropout_dense:\n",
        "                out = keras.layers.Dropout(dense_dropout_ratio[i])(out)\n",
        "\n",
        "    #define output layers\n",
        "    if batch_norm_out:\n",
        "        out = keras.layers.BatchNormalization()(out)\n",
        "    if dropout_out:\n",
        "        out = keras.layers.Dropout(out_dropout_ratio)(out)\n",
        "    output = keras.layers.Dense(units = out_units, activation = out_activation)(out)\n",
        "\n",
        "    if pretrained_input:\n",
        "        input = pretrained_model.input\n",
        "\n",
        "    model = keras.models.Model(input, output)\n",
        "\n",
        "    #define model compile\n",
        "    model.compile(optimizer = compile_optimizer,\n",
        "                  loss = compile_loss,\n",
        "                  metrics = compile_metric)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_xnYj4neVWVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define custom callbacks\n",
        "class callback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs = None):\n",
        "        self.model.save('/content/model.h5')\n",
        "        "
      ],
      "metadata": {
        "id": "AbKkF-OEvHwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model = create_model(#convolution layer configuration\n",
        "                     conv_layers_num = int(), conv_filters = list(), conv_kernel_size = list(),\n",
        "                     flatten_dropout_ratio = float(), \n",
        "                     #dense layer configuration\n",
        "                     dense_layers_num = int(), dense_units = list(), dense_dropout_ratio = list(), \n",
        "                     #output layer configuration\n",
        "                     out_dropout_ratio = float(), out_units = train_data.num_classes,\n",
        "                     #activations configuration\n",
        "                     conv_activation = 'relu', dense_activation = 'relu', out_activation = 'softmax',\n",
        "                     \n",
        "                     #input shape\n",
        "                     inp_shape = (Height, Width, 3),\n",
        "                     \n",
        "                     #compiling Configuration\n",
        "                     compile_optimizer = 'adam', compile_loss = 'sparse_categorical_crossentropy' ,\n",
        "                     compile_metric = ['accuracy'],\n",
        "                     \n",
        "                     #pretrained_model configuration\n",
        "                     flatten_input = None, pretrained_input = False,\n",
        "\n",
        "                     #convolution layers\n",
        "                     conv_base = True, batch_norm_conv = True,\n",
        "                     #flatten layer\n",
        "                     flatten_layer = True, flatten_dropout_out = True,                  \n",
        "                     #dense layers\n",
        "                     dense_head = True,  batch_norm_dense = True, dropout_dense = True,\n",
        "                     #output layer\n",
        "                     batch_norm_out = True, dropout_out = True\n",
        "                    )"
      ],
      "metadata": {
        "id": "Tu-f1qv2hBtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print model summary\n",
        "model.summary(120)\n"
      ],
      "metadata": {
        "id": "7tbypQCLA5Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model for training\n",
        "model.fit(train_data, validation_data = valid_data, epochs = 100,\n",
        "          callbacks = [keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True, monitor = 'val_accuracy'),\n",
        "                       keras.callbacks.CSVLogger('Log.csv', append = True),\n",
        "                       keras.callbacks.ReduceLROnPlateau('val_accuracy', patience = 3, factor = 0.1),\n",
        "                       keras.callbacks.ModelCheckpoint('/content/model-checkpoint')]\n",
        "          )\n"
      ],
      "metadata": {
        "id": "J3IZZX3i-6VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot model training loss\n",
        "pd.DataFrame(model.history.history)[['loss', 'val_loss']].plot(figsize = (9, 6), linewidth = 3)\n",
        "plt.grid(linestyle = '--', linewidth = 2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "15x7dLePYEHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot model training accuracy\n",
        "pd.DataFrame(model.history.history)[['accuracy', 'val_accuracy']].plot(figsize = (9, 6), linewidth = 3)\n",
        "plt.grid(linestyle = '--', linewidth = 2)\n",
        "plt.ylim(0,1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R59nQOxUxS64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "train_set_eval = model.evaluate(train_data, verbose = 0)\n",
        "valid_set_eval = model.evaluate(valid_data, verbose = 0)\n",
        "\n",
        "print(f'Training Set Evaluation:\\n\\tLoss: {round(train_set_eval[0],4)}\\tAccuracy: {100*round(train_set_eval[1],4)}%')\n",
        "print(f'Validation Set Evaluation:\\n\\tLoss: {round(valid_set_eval[0],4)}\\tAccuracy: {100*round(valid_set_eval[1],4)}%')\n"
      ],
      "metadata": {
        "id": "ImsHBVGAJ7nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make list of images for random prediction\n",
        "def image_file(dir_path):\n",
        "    image_list = list()\n",
        "    for root, dirs, files in os.walk(dir_path):\n",
        "        for file in files:\n",
        "            image_list.append(os.path.join(root, file))\n",
        "    return image_list\n"
      ],
      "metadata": {
        "id": "ztOCm0OHB6N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#draw random image\n",
        "img = image_file(dir_path)\n",
        "image = img\n",
        "img = keras.preprocessing.image.load_img(img, target_size = (Height, Width),\n",
        "                                         color_mode = 'rgb')\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "img = img/255\n",
        "plt.axis('off')\n",
        "plt.imshow(img)\n",
        "plt.title(image.split('/')[-1])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aXb7VGJVfIJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction for random image\n",
        "img = np.expand_dims(img, 0)\n",
        "print(model.predict(img))\n",
        "print(train_data.class_indices)\n"
      ],
      "metadata": {
        "id": "cuwHGS-WgK4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('/content/model.h5')\n"
      ],
      "metadata": {
        "id": "ABCDEFGHIJKL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}